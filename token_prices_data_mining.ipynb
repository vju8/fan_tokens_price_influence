{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7270fb4-458a-4767-84b8-e8a6e31dc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time \n",
    "import json \n",
    "import os\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e45dd-c7ae-4464-8345-7d673ff61ecc",
   "metadata": {},
   "source": [
    "# Data Mining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51d8c1d-dac9-4333-a727-1ee75c11566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_club_token_df(filename):\n",
    "    club_token_df = pd.read_csv(filepath_or_buffer = \"Raw Data/clubs_and_token_names.csv\", \n",
    "                                delimiter = \";\", \n",
    "                                header = 0)\n",
    "    return club_token_df\n",
    "\n",
    "def download_dataset(token_name): \n",
    "    \n",
    "    def construct_download_url(token_name):\n",
    "        \"\"\"\n",
    "        Interval Period used for data: period1 = 08.04.2018, period2 = 08.04.2023 (5 years)\n",
    "        \"\"\"\n",
    "        url = f'https://query1.finance.yahoo.com/v7/finance/download/{token_name}?period1=1525651200&period2=1683417600&interval=1d&events=history&includeAdjustedClose=true'\n",
    "        return url    \n",
    "    \n",
    "    def append_club(df):\n",
    "        # append the primary key fields to the dataframe for identification\n",
    "        df[\"Token_Name\"] = token_name\n",
    "        df[\"Club_Name\"] = df[\"Token_Name\"].map(club_token_mapping)\n",
    "        \n",
    "        df.reset_index(inplace = True)\n",
    "        # arange column in following order: Club_Name, Token_Name, Date, Open, High, Low, Close, Volume    \n",
    "        df = df[[\"Club_Name\", \"Token_Name\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "        return df\n",
    "    \n",
    "    # retrive dataset\n",
    "    try:\n",
    "        query_url = construct_download_url(token_name)\n",
    "        df = pd.read_csv(query_url)\n",
    "        df = append_club(df)\n",
    "        # save dataset as a CSV\n",
    "        df.to_csv(f\"Raw Data/Individual Token Historical Data/{token_name} Price Historical Data.csv\")    \n",
    "    except HTTPError:\n",
    "        print(token_name)\n",
    "        \n",
    "def concat_and_save_all_dfs():\n",
    "    csv_files = os.listdir(f\"{os.getcwd()}\\Raw Data\\Individual Token Historical Data\")\n",
    "    df_all = pd.concat([pd.read_csv(f\"Raw Data\\Individual Token Historical Data\\{file}\") for file in csv_files ], ignore_index=True)    \n",
    "    df_all.to_csv(f\"Raw Data\\All Fan Tokens Price Historical Data.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    club_token_df = generate_club_token_df(\"Raw Data\\clubs_and_token_names.csv\")\n",
    "    token_list = club_token_df[\"token_name\"].to_list()\n",
    "    club_token_mapping = dict(club_token_df[[\"token_name\", \"club_or_organisation_name\"]].values) \n",
    "    for token_name in token_list:\n",
    "        download_dataset(token_name) \n",
    "    concat_and_save_all_dfs()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
